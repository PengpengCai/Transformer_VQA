{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinghao/anaconda3/envs/xinghao/lib/python3.10/site-packages/torchvision/transforms/transforms.py:891: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.9303,  1.9303,  1.9303,  ...,  1.8719,  1.4632,  1.5216],\n",
      "         [ 1.9303,  1.9303,  1.9303,  ...,  1.7990,  1.6092,  1.6968],\n",
      "         [ 1.8573,  1.9303,  1.9303,  ...,  1.8135,  1.8573,  1.9157],\n",
      "         ...,\n",
      "         [-0.4346, -0.3762, -0.1864,  ..., -0.6098, -0.7412, -0.6828],\n",
      "         [-0.4346, -0.3762, -0.2448,  ..., -0.7850, -0.6682, -0.3470],\n",
      "         [-0.6536, -0.5076, -0.1864,  ..., -0.6536, -0.4638, -0.2886]],\n",
      "\n",
      "        [[ 1.6247,  1.5646,  1.6697,  ...,  1.5046,  1.0844,  1.1444],\n",
      "         [ 1.5046,  1.5196,  1.5946,  ...,  1.4446,  1.2645,  1.3395],\n",
      "         [ 1.4295,  1.5046,  1.6096,  ...,  1.4295,  1.4896,  1.5196],\n",
      "         ...,\n",
      "         [-0.3714, -0.2663, -0.0712,  ..., -0.5815, -0.7016, -0.5815],\n",
      "         [-0.3564, -0.2663, -0.0412,  ..., -0.8216, -0.6715, -0.2213],\n",
      "         [-0.5365, -0.3864,  0.0789,  ..., -0.6565, -0.4164, -0.1012]],\n",
      "\n",
      "        [[ 1.0510,  1.0083,  1.0510,  ...,  1.0083,  0.6244,  0.6812],\n",
      "         [ 1.0652,  1.0794,  1.0083,  ...,  0.9088,  0.6955,  0.8092],\n",
      "         [ 0.9514,  1.0083,  1.0794,  ...,  0.9656,  1.0225,  1.1221],\n",
      "         ...,\n",
      "         [-0.2857, -0.1862,  0.0840,  ..., -0.2857, -0.4564, -0.4848],\n",
      "         [-0.1720, -0.1293,  0.0271,  ..., -0.5559, -0.4564, -0.2146],\n",
      "         [-0.3426, -0.2146,  0.0982,  ..., -0.4564, -0.2857, -0.1151]]]), 'what position is this man playing', ['pitcher[SEP]', 'catcher[SEP]'], [0.8999999999999999, 0.1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from dataset.vqa_dataset import vqa_dataset\n",
    "# from dataset.grounding_dataset import grounding_dataset\n",
    "\n",
    "from dataset.randaugment import RandomAugment\n",
    "from utils import MetricLogger\n",
    "from dataset import create_dataset, create_sampler, create_loader, vqa_collate_fn,vqa_dataset\n",
    "\n",
    "normalize = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "    \n",
    "train_transform = transforms.Compose([                        \n",
    "            transforms.RandomResizedCrop(384,scale=(0.5, 1.0), interpolation=Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            RandomAugment(2,7,isPIL=True,augs=['Identity','AutoContrast','Equalize','Brightness','Sharpness',\n",
    "                                              'ShearX', 'ShearY', 'TranslateX', 'TranslateY', 'Rotate']),     \n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])  \n",
    "\n",
    "vqa_test_dataset = vqa_dataset(['/home/xinghao/code/datasets/vqa2/vqa_train.json'], train_transform, '/home/xinghao/code/datasets/vqa2', '', split='train') \n",
    "print(vqa_test_dataset.__getitem__(1))\n",
    "train_loader = create_loader((vqa_test_dataset,),[None],\n",
    "                                              batch_size=[3],\n",
    "                                              num_workers=[4],is_trains=[True], \n",
    "                                              collate_fns=[vqa_collate_fn])\n",
    "\n",
    "metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "# for i,(image, question, answer, weights, n) in enumerate(train_loader[0]):\n",
    "#     print(image, question, answer, weights, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([3.])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda kernel",
   "language": "python",
   "name": "xinghao"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd351a765210a1405fd883c4f2cdfcd3da8b1e3b4ebe50fea489a8691914f108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
